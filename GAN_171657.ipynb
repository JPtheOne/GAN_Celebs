{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1o4ttNM1c1UXhFL4Rl8bibCHoMkjx8dtM",
      "authorship_tag": "ABX9TyM+OKPLj8Hu7LInK9QvbG+p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JPtheOne/GAN_Celebs/blob/main/GAN_171657.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Keras implementation \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tEwk12Phivg2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Installing libraries"
      ],
      "metadata": {
        "id": "NfAxu0R-i3am"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnZwVcgBLr5T"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import gdown\n",
        "from zipfile import ZipFile"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Google Drive Mount"
      ],
      "metadata": {
        "id": "ofJpW2U5jIS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5Lu3D4kMTFg",
        "outputId": "38647d54-5bab-4fe0-da35-5fa2d3af9d47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Veryfing path"
      ],
      "metadata": {
        "id": "CdZ-aHRmjYTz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "folder_path = '/content/drive/MyDrive/Celeb10k/'\n",
        "image_files = os.listdir(folder_path)\n",
        "print(f'Number of images: {len(image_files)}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3WQjSfOOdIU",
        "outputId": "5db42676-e4f7-4aed-df2b-07e435c0abf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = keras.utils.image_dataset_from_directory(\n",
        "    folder_path, label_mode=None, image_size=(64, 64), batch_size=32)\n",
        "dataset = dataset.map(lambda x: x / 255.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77GJPwY6OlE0",
        "outputId": "9bf4f9ff-9f9d-4bbd-9ee8-a93c670937da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10000 files belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating dataset"
      ],
      "metadata": {
        "id": "rrSYZvncjtlZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for x in dataset:\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow((x.numpy() * 255).astype(\"int32\")[0])\n",
        "    break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "tM2-Pm4JOtoH",
        "outputId": "99fdc952-bca1-4529-bf66-199d0c9e8cd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining discriminator agent"
      ],
      "metadata": {
        "id": "vBqYkZ98j2VO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(64, 64, 3)),\n",
        "        layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(1, activation=\"sigmoid\"),\n",
        "    ],\n",
        "    name=\"discriminator\",\n",
        ")\n",
        "discriminator.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVrUwyPjPZYK",
        "outputId": "5b3edbfb-0aa8-420a-d5c9-c1e8fa907eb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"discriminator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 64)        3136      \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 16, 16, 128)       131200    \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 8, 8, 128)         262272    \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 8192)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 8192)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 8193      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 404,801\n",
            "Trainable params: 404,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining generator"
      ],
      "metadata": {
        "id": "8GP_hnEvj9mi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 128\n",
        "\n",
        "generator = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(latent_dim,)),\n",
        "        layers.Dense(8 * 8 * 128),\n",
        "        layers.Reshape((8, 8, 128)),\n",
        "        layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2DTranspose(512, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2D(3, kernel_size=5, padding=\"same\", activation=\"sigmoid\"),\n",
        "    ],\n",
        "    name=\"generator\",\n",
        ")\n",
        "generator.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vc-yWFpcPc6A",
        "outputId": "7e1f7032-1f96-4267-8dbf-872adad11ada"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"generator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1 (Dense)             (None, 8192)              1056768   \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 16, 16, 128)      262272    \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 32, 32, 256)      524544    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2DT  (None, 64, 64, 512)      2097664   \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " leaky_re_lu_5 (LeakyReLU)   (None, 64, 64, 512)       0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 64, 64, 3)         38403     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,979,651\n",
            "Trainable params: 3,979,651\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating training sessions"
      ],
      "metadata": {
        "id": "g8_KjBpYkGZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class GAN(keras.Model):\n",
        "    def __init__(self, discriminator, generator, latent_dim):\n",
        "        super().__init__()\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
        "        super().compile()\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.loss_fn = loss_fn\n",
        "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
        "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.d_loss_metric, self.g_loss_metric]\n",
        "\n",
        "    def train_step(self, real_images):\n",
        "        # Sample random points in the latent space\n",
        "        batch_size = tf.shape(real_images)[0]\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # Decode them to fake images\n",
        "        generated_images = self.generator(random_latent_vectors)\n",
        "\n",
        "        # Combine them with real images\n",
        "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
        "\n",
        "        # Assemble labels discriminating real from fake images\n",
        "        labels = tf.concat(\n",
        "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
        "        )\n",
        "        # Add random noise to the labels - important trick!\n",
        "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
        "\n",
        "        # Train the discriminator\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(combined_images)\n",
        "            d_loss = self.loss_fn(labels, predictions)\n",
        "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
        "        self.d_optimizer.apply_gradients(\n",
        "            zip(grads, self.discriminator.trainable_weights)\n",
        "        )\n",
        "\n",
        "        # Sample random points in the latent space\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # Assemble labels that say \"all real images\"\n",
        "        misleading_labels = tf.zeros((batch_size, 1))\n",
        "\n",
        "        # Train the generator (note that we should *not* update the weights\n",
        "        # of the discriminator)!\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
        "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
        "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
        "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
        "\n",
        "        # Update metrics\n",
        "        self.d_loss_metric.update_state(d_loss)\n",
        "        self.g_loss_metric.update_state(g_loss)\n",
        "        return {\n",
        "            \"d_loss\": self.d_loss_metric.result(),\n",
        "            \"g_loss\": self.g_loss_metric.result(),\n",
        "        }\n"
      ],
      "metadata": {
        "id": "KNFLiyjZPeF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving and indexing results"
      ],
      "metadata": {
        "id": "kO3ISQuNkPwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "class GANMonitor(keras.callbacks.Callback):\n",
        "    def __init__(self, num_img=3, latent_dim=128, save_dir=\"generated_images\"):\n",
        "        self.num_img = num_img\n",
        "        self.latent_dim = latent_dim\n",
        "        self.save_dir = save_dir\n",
        "        os.makedirs(self.save_dir, exist_ok=True)\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        grid_size = int(np.sqrt(self.num_img))\n",
        "        grid_height = grid_width = 64 * grid_size\n",
        "        grid = np.zeros((grid_height, grid_width, 3))\n",
        "        \n",
        "        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
        "        generated_images = self.model.generator(random_latent_vectors)\n",
        "        generated_images = (generated_images + 1) * 127.5\n",
        "        generated_images = generated_images.numpy().astype(np.uint8)\n",
        "        \n",
        "        for i, img in enumerate(generated_images):\n",
        "            x = (i % grid_size) * 64\n",
        "            y = (i // grid_size) * 64\n",
        "            grid[y:y + 64, x:x + 64] = img\n",
        "\n",
        "        img_path = os.path.join(self.save_dir, f\"image_grid_epoch_{epoch:03d}.png\")\n",
        "        keras.preprocessing.image.save_img(img_path, grid)\n"
      ],
      "metadata": {
        "id": "mrnmZaDtPiIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instancing trainings"
      ],
      "metadata": {
        "id": "XLv2sLhUkVs5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 500 # In practice, use ~100 epochs\n",
        "num_img = 16\n",
        "\n",
        "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
        "gan.compile(\n",
        "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    loss_fn=keras.losses.BinaryCrossentropy(),\n",
        ")\n",
        "\n",
        "gan.fit(\n",
        "    dataset, epochs=epochs, callbacks=[GANMonitor(num_img, latent_dim=latent_dim, save_dir=\"generated_images\")]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zt-V5u5VPkfO",
        "outputId": "afdd94ea-d63e-41a7-efa8-7ef1cbb83d25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "313/313 [==============================] - 13s 28ms/step - d_loss: 0.6100 - g_loss: 1.0007\n",
            "Epoch 2/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6243 - g_loss: 0.9917\n",
            "Epoch 3/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6190 - g_loss: 0.9890\n",
            "Epoch 4/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6126 - g_loss: 1.0001\n",
            "Epoch 5/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6194 - g_loss: 1.0043\n",
            "Epoch 6/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6118 - g_loss: 1.0039\n",
            "Epoch 7/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6216 - g_loss: 1.0118\n",
            "Epoch 8/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6193 - g_loss: 0.9931\n",
            "Epoch 9/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6207 - g_loss: 1.0005\n",
            "Epoch 10/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6322 - g_loss: 1.0200\n",
            "Epoch 11/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6176 - g_loss: 0.9809\n",
            "Epoch 12/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6233 - g_loss: 0.9841\n",
            "Epoch 13/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6142 - g_loss: 0.9755\n",
            "Epoch 14/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6239 - g_loss: 0.9716\n",
            "Epoch 15/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6104 - g_loss: 0.9987\n",
            "Epoch 16/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6167 - g_loss: 0.9919\n",
            "Epoch 17/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6151 - g_loss: 0.9854\n",
            "Epoch 18/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6136 - g_loss: 0.9830\n",
            "Epoch 19/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6158 - g_loss: 1.0026\n",
            "Epoch 20/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6082 - g_loss: 0.9776\n",
            "Epoch 21/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6177 - g_loss: 1.0337\n",
            "Epoch 22/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6160 - g_loss: 0.9668\n",
            "Epoch 23/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6096 - g_loss: 0.9903\n",
            "Epoch 24/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6340 - g_loss: 1.0121\n",
            "Epoch 25/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6157 - g_loss: 0.9848\n",
            "Epoch 26/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6185 - g_loss: 0.9680\n",
            "Epoch 27/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6124 - g_loss: 0.9629\n",
            "Epoch 28/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6180 - g_loss: 0.9786\n",
            "Epoch 29/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6135 - g_loss: 0.9823\n",
            "Epoch 30/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6205 - g_loss: 0.9830\n",
            "Epoch 31/500\n",
            "313/313 [==============================] - 9s 27ms/step - d_loss: 0.6278 - g_loss: 1.1090\n",
            "Epoch 32/500\n",
            "313/313 [==============================] - 9s 27ms/step - d_loss: 0.6914 - g_loss: 1.0938\n",
            "Epoch 33/500\n",
            "313/313 [==============================] - 9s 27ms/step - d_loss: 0.6354 - g_loss: 0.9818\n",
            "Epoch 34/500\n",
            "313/313 [==============================] - 9s 27ms/step - d_loss: 0.6197 - g_loss: 0.9910\n",
            "Epoch 35/500\n",
            "313/313 [==============================] - 9s 27ms/step - d_loss: 0.6036 - g_loss: 0.9910\n",
            "Epoch 36/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6107 - g_loss: 0.9757\n",
            "Epoch 37/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6081 - g_loss: 0.9778\n",
            "Epoch 38/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6113 - g_loss: 0.9742\n",
            "Epoch 39/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6083 - g_loss: 1.0113\n",
            "Epoch 40/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6040 - g_loss: 0.9966\n",
            "Epoch 41/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6152 - g_loss: 0.9883\n",
            "Epoch 42/500\n",
            "313/313 [==============================] - 9s 27ms/step - d_loss: 0.6067 - g_loss: 0.9862\n",
            "Epoch 43/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6053 - g_loss: 0.9970\n",
            "Epoch 44/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6040 - g_loss: 1.0593\n",
            "Epoch 45/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6082 - g_loss: 1.0223\n",
            "Epoch 46/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6046 - g_loss: 0.9790\n",
            "Epoch 47/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6169 - g_loss: 1.0702\n",
            "Epoch 48/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6181 - g_loss: 0.9954\n",
            "Epoch 49/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6122 - g_loss: 1.0017\n",
            "Epoch 50/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6068 - g_loss: 0.9987\n",
            "Epoch 51/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6137 - g_loss: 0.9934\n",
            "Epoch 52/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5999 - g_loss: 1.0347\n",
            "Epoch 53/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6012 - g_loss: 1.0430\n",
            "Epoch 54/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5990 - g_loss: 1.0293\n",
            "Epoch 55/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6010 - g_loss: 0.9840\n",
            "Epoch 56/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6045 - g_loss: 1.0125\n",
            "Epoch 57/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6055 - g_loss: 0.9862\n",
            "Epoch 58/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6032 - g_loss: 0.9919\n",
            "Epoch 59/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6130 - g_loss: 1.0681\n",
            "Epoch 60/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6067 - g_loss: 1.0369\n",
            "Epoch 61/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6017 - g_loss: 1.0077\n",
            "Epoch 62/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6037 - g_loss: 1.0209\n",
            "Epoch 63/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6038 - g_loss: 1.0158\n",
            "Epoch 64/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6035 - g_loss: 1.0230\n",
            "Epoch 65/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5972 - g_loss: 1.0018\n",
            "Epoch 66/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6020 - g_loss: 0.9926\n",
            "Epoch 67/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6020 - g_loss: 1.0147\n",
            "Epoch 68/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6004 - g_loss: 1.0021\n",
            "Epoch 69/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6056 - g_loss: 1.0303\n",
            "Epoch 70/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6007 - g_loss: 1.0175\n",
            "Epoch 71/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6023 - g_loss: 1.0147\n",
            "Epoch 72/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5990 - g_loss: 1.0207\n",
            "Epoch 73/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6050 - g_loss: 1.0014\n",
            "Epoch 74/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5995 - g_loss: 1.0341\n",
            "Epoch 75/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5938 - g_loss: 1.0084\n",
            "Epoch 76/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5959 - g_loss: 1.0166\n",
            "Epoch 77/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6032 - g_loss: 1.0056\n",
            "Epoch 78/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5973 - g_loss: 1.0709\n",
            "Epoch 79/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.6018 - g_loss: 1.0879\n",
            "Epoch 80/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5962 - g_loss: 1.0076\n",
            "Epoch 81/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5980 - g_loss: 1.0440\n",
            "Epoch 82/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5982 - g_loss: 1.0476\n",
            "Epoch 83/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5916 - g_loss: 1.0421\n",
            "Epoch 84/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5913 - g_loss: 1.0225\n",
            "Epoch 85/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5918 - g_loss: 1.0217\n",
            "Epoch 86/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5910 - g_loss: 1.0269\n",
            "Epoch 87/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5936 - g_loss: 1.0434\n",
            "Epoch 88/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5917 - g_loss: 1.0993\n",
            "Epoch 89/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5819 - g_loss: 1.0322\n",
            "Epoch 90/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5884 - g_loss: 1.0303\n",
            "Epoch 91/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5911 - g_loss: 1.0201\n",
            "Epoch 92/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5920 - g_loss: 1.0235\n",
            "Epoch 93/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5946 - g_loss: 1.0251\n",
            "Epoch 94/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5879 - g_loss: 1.0522\n",
            "Epoch 95/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5887 - g_loss: 1.0290\n",
            "Epoch 96/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5900 - g_loss: 1.0413\n",
            "Epoch 97/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5898 - g_loss: 1.0408\n",
            "Epoch 98/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5839 - g_loss: 1.0452\n",
            "Epoch 99/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5870 - g_loss: 1.0485\n",
            "Epoch 100/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5861 - g_loss: 1.0341\n",
            "Epoch 101/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5929 - g_loss: 1.0208\n",
            "Epoch 102/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5855 - g_loss: 1.0408\n",
            "Epoch 103/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5826 - g_loss: 1.0458\n",
            "Epoch 104/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5879 - g_loss: 1.0368\n",
            "Epoch 105/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5862 - g_loss: 1.0394\n",
            "Epoch 106/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5822 - g_loss: 1.0506\n",
            "Epoch 107/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5870 - g_loss: 1.0415\n",
            "Epoch 108/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5835 - g_loss: 1.0656\n",
            "Epoch 109/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5812 - g_loss: 1.0686\n",
            "Epoch 110/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5849 - g_loss: 1.0592\n",
            "Epoch 111/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5748 - g_loss: 1.1187\n",
            "Epoch 112/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5850 - g_loss: 1.0791\n",
            "Epoch 113/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5744 - g_loss: 1.0696\n",
            "Epoch 114/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5761 - g_loss: 1.0708\n",
            "Epoch 115/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5833 - g_loss: 1.0581\n",
            "Epoch 116/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5824 - g_loss: 1.0509\n",
            "Epoch 117/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5818 - g_loss: 1.0327\n",
            "Epoch 118/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5763 - g_loss: 1.0380\n",
            "Epoch 119/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5808 - g_loss: 1.0848\n",
            "Epoch 120/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5796 - g_loss: 1.0666\n",
            "Epoch 121/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5777 - g_loss: 1.0726\n",
            "Epoch 122/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5726 - g_loss: 1.0723\n",
            "Epoch 123/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5767 - g_loss: 1.0571\n",
            "Epoch 124/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5803 - g_loss: 1.0726\n",
            "Epoch 125/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5783 - g_loss: 1.0749\n",
            "Epoch 126/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5740 - g_loss: 1.0778\n",
            "Epoch 127/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5690 - g_loss: 1.0793\n",
            "Epoch 128/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5780 - g_loss: 1.0919\n",
            "Epoch 129/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5630 - g_loss: 1.0768\n",
            "Epoch 130/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5722 - g_loss: 1.0725\n",
            "Epoch 131/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5741 - g_loss: 1.0610\n",
            "Epoch 132/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5714 - g_loss: 1.0743\n",
            "Epoch 133/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5738 - g_loss: 1.0723\n",
            "Epoch 134/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5670 - g_loss: 1.0891\n",
            "Epoch 135/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5670 - g_loss: 1.0995\n",
            "Epoch 136/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5598 - g_loss: 1.1291\n",
            "Epoch 137/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5672 - g_loss: 1.0968\n",
            "Epoch 138/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5638 - g_loss: 1.0887\n",
            "Epoch 139/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5678 - g_loss: 1.1012\n",
            "Epoch 140/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5686 - g_loss: 1.0960\n",
            "Epoch 141/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5663 - g_loss: 1.0885\n",
            "Epoch 142/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5697 - g_loss: 1.0984\n",
            "Epoch 143/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5693 - g_loss: 1.0931\n",
            "Epoch 144/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5656 - g_loss: 1.1095\n",
            "Epoch 145/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5626 - g_loss: 1.0896\n",
            "Epoch 146/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5599 - g_loss: 1.1042\n",
            "Epoch 147/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5686 - g_loss: 1.1142\n",
            "Epoch 148/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5556 - g_loss: 1.1512\n",
            "Epoch 149/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5699 - g_loss: 1.1075\n",
            "Epoch 150/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5679 - g_loss: 1.0716\n",
            "Epoch 151/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5585 - g_loss: 1.0982\n",
            "Epoch 152/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5657 - g_loss: 1.1204\n",
            "Epoch 153/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5658 - g_loss: 1.1301\n",
            "Epoch 154/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5529 - g_loss: 1.1285\n",
            "Epoch 155/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5560 - g_loss: 1.1189\n",
            "Epoch 156/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5688 - g_loss: 1.1317\n",
            "Epoch 157/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5567 - g_loss: 1.1461\n",
            "Epoch 158/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5468 - g_loss: 1.2008\n",
            "Epoch 159/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5546 - g_loss: 1.1268\n",
            "Epoch 160/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5603 - g_loss: 1.1208\n",
            "Epoch 161/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5557 - g_loss: 1.1203\n",
            "Epoch 162/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5565 - g_loss: 1.1017\n",
            "Epoch 163/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5502 - g_loss: 1.1186\n",
            "Epoch 164/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5532 - g_loss: 1.1242\n",
            "Epoch 165/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5543 - g_loss: 1.1359\n",
            "Epoch 166/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5554 - g_loss: 1.1124\n",
            "Epoch 167/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5591 - g_loss: 1.1188\n",
            "Epoch 168/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5496 - g_loss: 1.1377\n",
            "Epoch 169/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5500 - g_loss: 1.1202\n",
            "Epoch 170/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5527 - g_loss: 1.1444\n",
            "Epoch 171/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5504 - g_loss: 1.1288\n",
            "Epoch 172/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5470 - g_loss: 1.1311\n",
            "Epoch 173/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5498 - g_loss: 1.1237\n",
            "Epoch 174/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5467 - g_loss: 1.1303\n",
            "Epoch 175/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5519 - g_loss: 1.1362\n",
            "Epoch 176/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5488 - g_loss: 1.1550\n",
            "Epoch 177/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5450 - g_loss: 1.1173\n",
            "Epoch 178/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5427 - g_loss: 1.1424\n",
            "Epoch 179/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5479 - g_loss: 1.1234\n",
            "Epoch 180/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5391 - g_loss: 1.1294\n",
            "Epoch 181/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5511 - g_loss: 1.1592\n",
            "Epoch 182/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5429 - g_loss: 1.1426\n",
            "Epoch 183/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5482 - g_loss: 1.1353\n",
            "Epoch 184/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5456 - g_loss: 1.1319\n",
            "Epoch 185/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5444 - g_loss: 1.1679\n",
            "Epoch 186/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5409 - g_loss: 1.1495\n",
            "Epoch 187/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5429 - g_loss: 1.1486\n",
            "Epoch 188/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5424 - g_loss: 1.1697\n",
            "Epoch 189/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5380 - g_loss: 1.1607\n",
            "Epoch 190/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5438 - g_loss: 1.1485\n",
            "Epoch 191/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5352 - g_loss: 1.2152\n",
            "Epoch 192/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5432 - g_loss: 1.1739\n",
            "Epoch 193/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5338 - g_loss: 1.1671\n",
            "Epoch 194/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5506 - g_loss: 1.1700\n",
            "Epoch 195/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5330 - g_loss: 1.1971\n",
            "Epoch 196/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5356 - g_loss: 1.2247\n",
            "Epoch 197/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5325 - g_loss: 1.1488\n",
            "Epoch 198/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5430 - g_loss: 1.1480\n",
            "Epoch 199/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5327 - g_loss: 1.1662\n",
            "Epoch 200/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5338 - g_loss: 1.1921\n",
            "Epoch 201/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5368 - g_loss: 1.1483\n",
            "Epoch 202/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5361 - g_loss: 1.1889\n",
            "Epoch 203/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5296 - g_loss: 1.2072\n",
            "Epoch 204/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5310 - g_loss: 1.1899\n",
            "Epoch 205/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5316 - g_loss: 1.1748\n",
            "Epoch 206/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5384 - g_loss: 1.1865\n",
            "Epoch 207/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5378 - g_loss: 1.2030\n",
            "Epoch 208/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5301 - g_loss: 1.1747\n",
            "Epoch 209/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5337 - g_loss: 1.1718\n",
            "Epoch 210/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5312 - g_loss: 1.1848\n",
            "Epoch 211/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5278 - g_loss: 1.2033\n",
            "Epoch 212/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5258 - g_loss: 1.2530\n",
            "Epoch 213/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5298 - g_loss: 1.2121\n",
            "Epoch 214/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5230 - g_loss: 1.1916\n",
            "Epoch 215/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5268 - g_loss: 1.1866\n",
            "Epoch 216/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5285 - g_loss: 1.1891\n",
            "Epoch 217/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5306 - g_loss: 1.2008\n",
            "Epoch 218/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5240 - g_loss: 1.1941\n",
            "Epoch 219/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5206 - g_loss: 1.2352\n",
            "Epoch 220/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5341 - g_loss: 1.1866\n",
            "Epoch 221/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5311 - g_loss: 1.2209\n",
            "Epoch 222/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5237 - g_loss: 1.1989\n",
            "Epoch 223/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5251 - g_loss: 1.2032\n",
            "Epoch 224/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5208 - g_loss: 1.1901\n",
            "Epoch 225/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5237 - g_loss: 1.2127\n",
            "Epoch 226/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5255 - g_loss: 1.2100\n",
            "Epoch 227/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5224 - g_loss: 1.1999\n",
            "Epoch 228/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5207 - g_loss: 1.2048\n",
            "Epoch 229/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5219 - g_loss: 1.2206\n",
            "Epoch 230/500\n",
            "313/313 [==============================] - 9s 27ms/step - d_loss: 0.5212 - g_loss: 1.2063\n",
            "Epoch 231/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5146 - g_loss: 1.2409\n",
            "Epoch 232/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5256 - g_loss: 1.2234\n",
            "Epoch 233/500\n",
            "313/313 [==============================] - 9s 27ms/step - d_loss: 0.5237 - g_loss: 1.2202\n",
            "Epoch 234/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5141 - g_loss: 1.2187\n",
            "Epoch 235/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5264 - g_loss: 1.2748\n",
            "Epoch 236/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5219 - g_loss: 1.2188\n",
            "Epoch 237/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5155 - g_loss: 1.2403\n",
            "Epoch 238/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5251 - g_loss: 1.2085\n",
            "Epoch 239/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5150 - g_loss: 1.2291\n",
            "Epoch 240/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5221 - g_loss: 1.2060\n",
            "Epoch 241/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5029 - g_loss: 1.2584\n",
            "Epoch 242/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5175 - g_loss: 1.2395\n",
            "Epoch 243/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5110 - g_loss: 1.2387\n",
            "Epoch 244/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5155 - g_loss: 1.2325\n",
            "Epoch 245/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5111 - g_loss: 1.2284\n",
            "Epoch 246/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5144 - g_loss: 1.2199\n",
            "Epoch 247/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5202 - g_loss: 1.2387\n",
            "Epoch 248/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5116 - g_loss: 1.2390\n",
            "Epoch 249/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5088 - g_loss: 1.2431\n",
            "Epoch 250/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5098 - g_loss: 1.2751\n",
            "Epoch 251/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5039 - g_loss: 1.2505\n",
            "Epoch 252/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5119 - g_loss: 1.2560\n",
            "Epoch 253/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5068 - g_loss: 1.2490\n",
            "Epoch 254/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5090 - g_loss: 1.2597\n",
            "Epoch 255/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5064 - g_loss: 1.2363\n",
            "Epoch 256/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5088 - g_loss: 1.2475\n",
            "Epoch 257/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5078 - g_loss: 1.2708\n",
            "Epoch 258/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5099 - g_loss: 1.2863\n",
            "Epoch 259/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5113 - g_loss: 1.2433\n",
            "Epoch 260/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5030 - g_loss: 1.2427\n",
            "Epoch 261/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5039 - g_loss: 1.2757\n",
            "Epoch 262/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5097 - g_loss: 1.2353\n",
            "Epoch 263/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5007 - g_loss: 1.2946\n",
            "Epoch 264/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5036 - g_loss: 1.2715\n",
            "Epoch 265/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5002 - g_loss: 1.2738\n",
            "Epoch 266/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5050 - g_loss: 1.2588\n",
            "Epoch 267/500\n",
            "313/313 [==============================] - 9s 27ms/step - d_loss: 0.4996 - g_loss: 1.3127\n",
            "Epoch 268/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5014 - g_loss: 1.2828\n",
            "Epoch 269/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5000 - g_loss: 1.2563\n",
            "Epoch 270/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5015 - g_loss: 1.2823\n",
            "Epoch 271/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4951 - g_loss: 1.2768\n",
            "Epoch 272/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5007 - g_loss: 1.2871\n",
            "Epoch 273/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.5029 - g_loss: 1.2659\n",
            "Epoch 274/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4951 - g_loss: 1.2773\n",
            "Epoch 275/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4975 - g_loss: 1.2747\n",
            "Epoch 276/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4935 - g_loss: 1.2889\n",
            "Epoch 277/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4980 - g_loss: 1.3128\n",
            "Epoch 278/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4966 - g_loss: 1.2856\n",
            "Epoch 279/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4975 - g_loss: 1.2771\n",
            "Epoch 280/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4983 - g_loss: 1.2809\n",
            "Epoch 281/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4964 - g_loss: 1.2932\n",
            "Epoch 282/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4893 - g_loss: 1.3043\n",
            "Epoch 283/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4954 - g_loss: 1.3297\n",
            "Epoch 284/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4865 - g_loss: 1.2895\n",
            "Epoch 285/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4933 - g_loss: 1.2834\n",
            "Epoch 286/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4948 - g_loss: 1.2912\n",
            "Epoch 287/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4904 - g_loss: 1.3004\n",
            "Epoch 288/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4924 - g_loss: 1.2944\n",
            "Epoch 289/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4834 - g_loss: 1.3243\n",
            "Epoch 290/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4963 - g_loss: 1.2965\n",
            "Epoch 291/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4887 - g_loss: 1.3169\n",
            "Epoch 292/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4911 - g_loss: 1.3200\n",
            "Epoch 293/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4921 - g_loss: 1.3353\n",
            "Epoch 294/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4993 - g_loss: 1.3452\n",
            "Epoch 295/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4879 - g_loss: 1.3174\n",
            "Epoch 296/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4860 - g_loss: 1.3009\n",
            "Epoch 297/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4894 - g_loss: 1.3138\n",
            "Epoch 298/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4900 - g_loss: 1.3084\n",
            "Epoch 299/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4884 - g_loss: 1.3343\n",
            "Epoch 300/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4789 - g_loss: 1.3259\n",
            "Epoch 301/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4840 - g_loss: 1.3344\n",
            "Epoch 302/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4785 - g_loss: 1.3402\n",
            "Epoch 303/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4906 - g_loss: 1.3224\n",
            "Epoch 304/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4837 - g_loss: 1.3324\n",
            "Epoch 305/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4816 - g_loss: 1.3259\n",
            "Epoch 306/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4757 - g_loss: 1.3371\n",
            "Epoch 307/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4790 - g_loss: 1.3279\n",
            "Epoch 308/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4860 - g_loss: 1.3412\n",
            "Epoch 309/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4756 - g_loss: 1.3677\n",
            "Epoch 310/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4783 - g_loss: 1.3229\n",
            "Epoch 311/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4789 - g_loss: 1.3292\n",
            "Epoch 312/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4802 - g_loss: 1.3490\n",
            "Epoch 313/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4794 - g_loss: 1.3595\n",
            "Epoch 314/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4815 - g_loss: 1.3508\n",
            "Epoch 315/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4765 - g_loss: 1.3465\n",
            "Epoch 316/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4714 - g_loss: 1.3489\n",
            "Epoch 317/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4739 - g_loss: 1.3478\n",
            "Epoch 318/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4750 - g_loss: 1.3417\n",
            "Epoch 319/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4684 - g_loss: 1.3611\n",
            "Epoch 320/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4756 - g_loss: 1.3778\n",
            "Epoch 321/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4706 - g_loss: 1.3698\n",
            "Epoch 322/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4694 - g_loss: 1.3691\n",
            "Epoch 323/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4704 - g_loss: 1.3655\n",
            "Epoch 324/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4691 - g_loss: 1.3746\n",
            "Epoch 325/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4736 - g_loss: 1.4037\n",
            "Epoch 326/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4645 - g_loss: 1.3790\n",
            "Epoch 327/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4649 - g_loss: 1.3637\n",
            "Epoch 328/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4769 - g_loss: 1.3750\n",
            "Epoch 329/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4675 - g_loss: 1.3576\n",
            "Epoch 330/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4719 - g_loss: 1.3727\n",
            "Epoch 331/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4612 - g_loss: 1.4098\n",
            "Epoch 332/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4641 - g_loss: 1.3673\n",
            "Epoch 333/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4712 - g_loss: 1.3668\n",
            "Epoch 334/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4640 - g_loss: 1.3859\n",
            "Epoch 335/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4652 - g_loss: 1.3849\n",
            "Epoch 336/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4627 - g_loss: 1.3987\n",
            "Epoch 337/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4625 - g_loss: 1.4042\n",
            "Epoch 338/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4552 - g_loss: 1.4141\n",
            "Epoch 339/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4573 - g_loss: 1.3994\n",
            "Epoch 340/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4613 - g_loss: 1.4120\n",
            "Epoch 341/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4597 - g_loss: 1.4263\n",
            "Epoch 342/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4579 - g_loss: 1.3935\n",
            "Epoch 343/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4577 - g_loss: 1.4069\n",
            "Epoch 344/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4548 - g_loss: 1.4127\n",
            "Epoch 345/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4631 - g_loss: 1.3884\n",
            "Epoch 346/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4509 - g_loss: 1.4059\n",
            "Epoch 347/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4568 - g_loss: 1.4150\n",
            "Epoch 348/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4613 - g_loss: 1.4111\n",
            "Epoch 349/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4563 - g_loss: 1.4013\n",
            "Epoch 350/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4562 - g_loss: 1.4166\n",
            "Epoch 351/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4555 - g_loss: 1.4305\n",
            "Epoch 352/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4500 - g_loss: 1.4292\n",
            "Epoch 353/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4563 - g_loss: 1.4217\n",
            "Epoch 354/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4492 - g_loss: 1.4444\n",
            "Epoch 355/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4559 - g_loss: 1.4088\n",
            "Epoch 356/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4516 - g_loss: 1.4282\n",
            "Epoch 357/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4440 - g_loss: 1.4338\n",
            "Epoch 358/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4593 - g_loss: 1.4290\n",
            "Epoch 359/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4495 - g_loss: 1.4308\n",
            "Epoch 360/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4482 - g_loss: 1.4417\n",
            "Epoch 361/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4475 - g_loss: 1.4412\n",
            "Epoch 362/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4473 - g_loss: 1.4673\n",
            "Epoch 363/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4434 - g_loss: 1.4675\n",
            "Epoch 364/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4491 - g_loss: 1.4757\n",
            "Epoch 365/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4474 - g_loss: 1.4535\n",
            "Epoch 366/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4469 - g_loss: 1.4785\n",
            "Epoch 367/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4448 - g_loss: 1.4800\n",
            "Epoch 368/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4438 - g_loss: 1.4745\n",
            "Epoch 369/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4466 - g_loss: 1.4350\n",
            "Epoch 370/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4474 - g_loss: 1.4570\n",
            "Epoch 371/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4399 - g_loss: 1.4694\n",
            "Epoch 372/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4403 - g_loss: 1.4691\n",
            "Epoch 373/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4397 - g_loss: 1.4465\n",
            "Epoch 374/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4404 - g_loss: 1.4798\n",
            "Epoch 375/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4337 - g_loss: 1.5003\n",
            "Epoch 376/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4402 - g_loss: 1.4782\n",
            "Epoch 377/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4427 - g_loss: 1.4808\n",
            "Epoch 378/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4396 - g_loss: 1.4719\n",
            "Epoch 379/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4363 - g_loss: 1.4837\n",
            "Epoch 380/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4391 - g_loss: 1.4700\n",
            "Epoch 381/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4375 - g_loss: 1.4876\n",
            "Epoch 382/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4366 - g_loss: 1.5021\n",
            "Epoch 383/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4342 - g_loss: 1.4776\n",
            "Epoch 384/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4336 - g_loss: 1.4978\n",
            "Epoch 385/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4365 - g_loss: 1.5008\n",
            "Epoch 386/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4336 - g_loss: 1.4876\n",
            "Epoch 387/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4348 - g_loss: 1.5033\n",
            "Epoch 388/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4363 - g_loss: 1.4861\n",
            "Epoch 389/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4314 - g_loss: 1.5053\n",
            "Epoch 390/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4329 - g_loss: 1.4949\n",
            "Epoch 391/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4336 - g_loss: 1.5015\n",
            "Epoch 392/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4228 - g_loss: 1.5264\n",
            "Epoch 393/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4286 - g_loss: 1.5152\n",
            "Epoch 394/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4275 - g_loss: 1.4935\n",
            "Epoch 395/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4261 - g_loss: 1.5147\n",
            "Epoch 396/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4243 - g_loss: 1.5205\n",
            "Epoch 397/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4252 - g_loss: 1.5161\n",
            "Epoch 398/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4294 - g_loss: 1.5148\n",
            "Epoch 399/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4261 - g_loss: 1.5125\n",
            "Epoch 400/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4299 - g_loss: 1.5092\n",
            "Epoch 401/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4246 - g_loss: 1.5179\n",
            "Epoch 402/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4296 - g_loss: 1.5246\n",
            "Epoch 403/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4232 - g_loss: 1.5292\n",
            "Epoch 404/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4223 - g_loss: 1.5357\n",
            "Epoch 405/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4211 - g_loss: 1.5308\n",
            "Epoch 406/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4227 - g_loss: 1.5370\n",
            "Epoch 407/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4241 - g_loss: 1.5525\n",
            "Epoch 408/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4235 - g_loss: 1.5313\n",
            "Epoch 409/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4203 - g_loss: 1.5257\n",
            "Epoch 410/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4205 - g_loss: 1.5313\n",
            "Epoch 411/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4175 - g_loss: 1.5566\n",
            "Epoch 412/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4204 - g_loss: 1.5469\n",
            "Epoch 413/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4202 - g_loss: 1.5375\n",
            "Epoch 414/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4153 - g_loss: 1.5423\n",
            "Epoch 415/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4168 - g_loss: 1.5501\n",
            "Epoch 416/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4149 - g_loss: 1.5726\n",
            "Epoch 417/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4150 - g_loss: 1.5639\n",
            "Epoch 418/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4153 - g_loss: 1.5885\n",
            "Epoch 419/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4166 - g_loss: 1.5715\n",
            "Epoch 420/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4120 - g_loss: 1.5895\n",
            "Epoch 421/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4153 - g_loss: 1.5571\n",
            "Epoch 422/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4142 - g_loss: 1.5949\n",
            "Epoch 423/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4210 - g_loss: 1.5769\n",
            "Epoch 424/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4134 - g_loss: 1.5941\n",
            "Epoch 425/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4108 - g_loss: 1.5791\n",
            "Epoch 426/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4079 - g_loss: 1.5924\n",
            "Epoch 427/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4110 - g_loss: 1.6019\n",
            "Epoch 428/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4151 - g_loss: 1.5849\n",
            "Epoch 429/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4122 - g_loss: 1.5830\n",
            "Epoch 430/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4063 - g_loss: 1.5864\n",
            "Epoch 431/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4070 - g_loss: 1.5952\n",
            "Epoch 432/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4104 - g_loss: 1.6113\n",
            "Epoch 433/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4092 - g_loss: 1.5948\n",
            "Epoch 434/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4059 - g_loss: 1.6036\n",
            "Epoch 435/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4044 - g_loss: 1.6044\n",
            "Epoch 436/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4086 - g_loss: 1.5873\n",
            "Epoch 437/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4041 - g_loss: 1.6184\n",
            "Epoch 438/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4032 - g_loss: 1.6210\n",
            "Epoch 439/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4030 - g_loss: 1.5940\n",
            "Epoch 440/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4054 - g_loss: 1.6124\n",
            "Epoch 441/500\n",
            "313/313 [==============================] - 9s 27ms/step - d_loss: 0.4037 - g_loss: 1.6104\n",
            "Epoch 442/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4001 - g_loss: 1.6221\n",
            "Epoch 443/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4010 - g_loss: 1.6191\n",
            "Epoch 444/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4014 - g_loss: 1.6527\n",
            "Epoch 445/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4030 - g_loss: 1.6164\n",
            "Epoch 446/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4047 - g_loss: 1.6169\n",
            "Epoch 447/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4073 - g_loss: 1.6266\n",
            "Epoch 448/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3960 - g_loss: 1.6371\n",
            "Epoch 449/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3958 - g_loss: 1.6277\n",
            "Epoch 450/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.4059 - g_loss: 1.6492\n",
            "Epoch 451/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3943 - g_loss: 1.6626\n",
            "Epoch 452/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3954 - g_loss: 1.6454\n",
            "Epoch 453/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3972 - g_loss: 1.6655\n",
            "Epoch 454/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3971 - g_loss: 1.6341\n",
            "Epoch 455/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3956 - g_loss: 1.6373\n",
            "Epoch 456/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3893 - g_loss: 1.6568\n",
            "Epoch 457/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3973 - g_loss: 1.6377\n",
            "Epoch 458/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3822 - g_loss: 1.6600\n",
            "Epoch 459/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3962 - g_loss: 1.6336\n",
            "Epoch 460/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3931 - g_loss: 1.6523\n",
            "Epoch 461/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3960 - g_loss: 1.6554\n",
            "Epoch 462/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3956 - g_loss: 1.6680\n",
            "Epoch 463/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3940 - g_loss: 1.6680\n",
            "Epoch 464/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3918 - g_loss: 1.6824\n",
            "Epoch 465/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3916 - g_loss: 1.6970\n",
            "Epoch 466/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3858 - g_loss: 1.6685\n",
            "Epoch 467/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3900 - g_loss: 1.6736\n",
            "Epoch 468/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3886 - g_loss: 1.6647\n",
            "Epoch 469/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3892 - g_loss: 1.6800\n",
            "Epoch 470/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3863 - g_loss: 1.6850\n",
            "Epoch 471/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3881 - g_loss: 1.6845\n",
            "Epoch 472/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3860 - g_loss: 1.6908\n",
            "Epoch 473/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3882 - g_loss: 1.6796\n",
            "Epoch 474/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3900 - g_loss: 1.6896\n",
            "Epoch 475/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3840 - g_loss: 1.6860\n",
            "Epoch 476/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3891 - g_loss: 1.6788\n",
            "Epoch 477/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3843 - g_loss: 1.6967\n",
            "Epoch 478/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3879 - g_loss: 1.7122\n",
            "Epoch 479/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3830 - g_loss: 1.6925\n",
            "Epoch 480/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3841 - g_loss: 1.7059\n",
            "Epoch 481/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3815 - g_loss: 1.7135\n",
            "Epoch 482/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3850 - g_loss: 1.7282\n",
            "Epoch 483/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3795 - g_loss: 1.7133\n",
            "Epoch 484/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3804 - g_loss: 1.7015\n",
            "Epoch 485/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3746 - g_loss: 1.7018\n",
            "Epoch 486/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3766 - g_loss: 1.7361\n",
            "Epoch 487/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3792 - g_loss: 1.7102\n",
            "Epoch 488/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3819 - g_loss: 1.7251\n",
            "Epoch 489/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3738 - g_loss: 1.7402\n",
            "Epoch 490/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3768 - g_loss: 1.7288\n",
            "Epoch 491/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3879 - g_loss: 1.7194\n",
            "Epoch 492/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3713 - g_loss: 1.7349\n",
            "Epoch 493/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3792 - g_loss: 1.7334\n",
            "Epoch 494/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3761 - g_loss: 1.7684\n",
            "Epoch 495/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3809 - g_loss: 1.7495\n",
            "Epoch 496/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3779 - g_loss: 1.7414\n",
            "Epoch 497/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3699 - g_loss: 1.7508\n",
            "Epoch 498/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3748 - g_loss: 1.7330\n",
            "Epoch 499/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3710 - g_loss: 1.7327\n",
            "Epoch 500/500\n",
            "313/313 [==============================] - 9s 28ms/step - d_loss: 0.3694 - g_loss: 1.7564\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7feca0f36280>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GIF Creator"
      ],
      "metadata": {
        "id": "C1-JcF6Dlw_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio\n",
        "\n",
        "def create_gif(epochs, save_dir, gif_filename):\n",
        "    # Collect the image file names for each epoch\n",
        "    filenames = []\n",
        "    for i in range(1, epochs):\n",
        "        filenames.append(os.path.join(save_dir, f\"image_grid_epoch_{i:03d}.png\"))\n",
        "\n",
        "    # Create the GIF using imageio\n",
        "    images = []\n",
        "    for filename in filenames:\n",
        "        images.append(imageio.imread(filename))\n",
        "    imageio.mimsave(gif_filename, images, fps=2)\n",
        "\n",
        "# Example usage:\n",
        "create_gif(500, \"generated_images\", \"generated_images.gif\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xX5UpqKxhy0x",
        "outputId": "cd10870d-d135-4fc7-b343-5bc9f510709c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-c341745b77fa>:12: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  images.append(imageio.imread(filename))\n"
          ]
        }
      ]
    }
  ]
}